<!-- posts/post6.html -->

<!DOCTYPE html>
<html>
  <head>
    <title>On consciousness simulation</title>
    <link rel="stylesheet" href="../css/styles.css" />
  </head>
  <body>
    <button id="home-button">Home</button>
    <button id="prev-button">Previous</button>
    <button id="next-button">Next</but    <button id="home-button">Home</button>
    <button id="prev-button">Previous</button>
    <button id="next-button">Next</button>ton>
    <h1>On consciousness simulation</h1> 
    <p>
      A simulation consists in encoding some properties of a system into a different system
      and put rules in place to replicate some subset of the dynamics of the simulated system.

      The crux of the matter here is that encodings lack the same ontological causality that
      applies to the real systems that are being simulated, because in a simulation the mechanism
      that transitions between the encoded states is determined by the an algorithm, not by the
      ontological embodiment of the states
    </p>
    <p>
      An argument that I encounter often is some variation of "you can simulate a bottle of
      water as well as you desire, but you still can't drink it."

      This is true, but remember that while many things are different than their description,
      some others are identical to their description, and so their simulation is as good as
      the real thing.
      
      For example a text file living in my usb stick can be copied and there's no "original" file
      that is any special.
      
      Any copy is the same, even if it runs of different platforms and under different encodings.
      
      In that case the "thing" is the information, not the substrate on which it lives.
      
      Is consciousness identical to its description? If it is, then sure it's simulable and
      it doesn't matter which substrate this happens in, but then we run into absurdities like
      the ones that were mentioned in the previous post.
    </p>
    <p>
      There are no reasons to believe that describing consciousness in any way will instantiate one.
      If it were, then <a href="https://en.wikipedia.org/wiki/Knowledge_argument">Mary the scientist</a>
      would learn nothing new by seeing red for the first time.

      V. S. Ramachandran in his book <em>phantoms in the brain</em> wrote something that I often
      find myself going back to.
      
      Paraphrasing, he says the problem of qualia could be a problem of
      language: if it's impossible to communicate my subjective experience through the bottleneck
      of natural language, what if we could connect our brains through some 'cable' that allows
      for a different kind of communication?

      This is an interesting question, but it kind of disproves this point because if consciousness
      was about information and its processing, then it should not matter how the information is 
      endcoded.
    </p>
    <script src="/js/button.js"></script>
  </body>
</html>
