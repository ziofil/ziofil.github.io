<!-- posts/post6.html -->

<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
    <title>On consciousness simulation</title>
    <link rel="stylesheet" href="../css/styles.css" />
    <script src="../js/darkMode.js"></script>
  </head>
  <body>
    <div class="header-container">
      <h1>On consciousness simulation</h1>
      <button id="darkModeToggle" class="dark-mode-toggle" aria-label="Toggle dark mode">&#127769;</button>
    </div>
    <button id="home-button">Home</button>
    <button id="prev-button">Previous</button>
    <button id="next-button">Next</button>
    <p>
      A simulation consists in encoding some properties of a system into a second system
      and put rules in place to replicate a subset of the dynamics of the first.

      Note though that encodings lack the same ontological causality that applies to the real
      systems that are being simulated, because in a simulation the mechanism that governs the 
      transitions between the encoded states is determined by the an algorithm, not by the
      ontological nature of the simulacrum. In other words, in order to carry out a simulation all
      is needed is coordination, not causation.
    </p>
    <p>
      A common argument for distinguishing a simulation from the thing being simulated is some
      variation of "you can simulate a bottle of water as well as you desire, but you still
      can't drink it."

      This is true, but remember that while many things are different than their description, some
      others are <em>identical</em> to their description, and so their simulation is as good as
      the real thing.
      
      For example a text file living in my usb stick can be copied and the "original" file is no
      more special.
      
      Any copy is the same, even if it is encoded in a different way and it runs of a different
      platform.
      
      In that case the "thing" is the information, not the substrate on which it lives.
      
      Is consciousness identical to its description? If it is, then it's simulable and it doesn't
      matter which substrate this happens in, but then one runs into the difficulties mentioned in 
      the previous post.
    </p>
    <p>
      Maintaining that a simulation of consciousness would be conscious needs consciousness to be
      the same as its description and implies that we could instantiate a consciousness by completely
      describing it.

      If this were the case, then <a href="https://en.wikipedia.org/wiki/Knowledge_argument">Mary
      the scientist</a> would learn nothing new by seeing red for the first time.

      This is explored in a slightly different light by V. S. Ramachandran in his book <em>phantoms
      in the brain</em>.
      
      Paraphrasing, he says the problem of qualia could be a problem of language: if it's impossible
      to communicate my subjective experience through the bottleneck of natural language, what if we
      could connect our brains through some 'cable' that allows for a different kind of communication?

      This is an interesting question, but if consciousness were just about information and its
      processing, then it should not matter how the information is encoded or transmitted, only
      what information. Therefore, natural language would be sufficient to communicate qualia.
    </p>
    <script src="../js/button.js"></script>
  </body>
</html>
