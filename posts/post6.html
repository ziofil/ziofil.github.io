<!-- posts/post6.html -->

<!DOCTYPE html>
<html>
  <head>
    <title>On consciousness simulation</title>
    <link rel="stylesheet" href="../css/styles.css" />
  </head>
  <body>
    <button id="back-button">Back</button>
    <h1>On consciousness simulation</h1> 
    <p>
      A simulation consists in encoding some of the properties of a system onto a different one
      and then replicating some subset of the dynamics of the original system.

      The crucial aspect of a simulation is that encodings lack the same ontological causality that
      applies to the actual systems that are being simulated, because in a simulation the mechanism
      that governs the transitions between the encoded states is determined by the an algorithm,
      not by the ontological essence of the system itself.

      In fact, in order for a simulation to be carried out, we only need <em>coordination</em>
      between the components of the simulation, not direct causal connections.

      This to me indicates that it's not at all obvious that a simulation of the brain would
      be conscious.
    </p>
    <p>
      An argument that people often make when they want to point out the difference in kind
      between simulacrum and simulata, is some variation of "you can simulate a bottle of
      water as well as you want, but you still can't drink it."

      This is true, but I think there is a better way to talk about this.
      
      Remember that while many things are indeed different than their description, some others are
      identical to their description, and so their simulation can be as good as the real thing.

      Usually things defined through information are like this.
      
      For example a text file living in my usb stick can be copied and there's no "original"
      file that is any special: any copy is the same, even if it runs of different platforms
      and under different encodings.
      
      In that case the "thing" is the information, not the substrate on which it lives or the
      machinery needed to make use of it.
      
      Is consciousness identical to its description? If it is, then it's simulable and it doesn't
      matter on which substrate this happens, but then we run into absurdities like the ones that
      were mentioned in the previous post.
    </p>
    <p>
      V. S. Ramachandran in his book <em>phantoms in the brain</em> wrote (paraphrasing) that the
      problem of qualia could be a problem of language: if it's impossible to communicate my
      subjective experience through the bottleneck of natural language, what if we could connect
      our brains through some 'cable' that allows for a different kind of communication?

      This is an interesting question, but if consciousness was about information and its
      processing, then it should not matter how the information is encoded.
      
      It might just take longer to communicate it through natural language, but it should still
      be possible in the end.
      
      Since it seems not to be possible, then probably consciousness is not about information and
      its processing.
    </p>
    <p>
      There are no reasons to believe that describing consciousness in any way will instantiate
      one.
      
      If it were, then <a href="https://en.wikipedia.org/wiki/Knowledge_argument">Mary the
      scientist</a> would learn nothing new by seeing red for the first time.
        
      This isn't a watertight argument against simulability, but it would be striking if it were
      true.
    </p>
    <script src="/js/button.js"></script>
  </body>
</html>
